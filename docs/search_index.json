[["imputation.html", "Imputation Intro 1. Extract LiDAR attributes in FRI polygons and newly derived polygons 1a. Extract attributes in FRI polygons 1b. Extract attributes in newly segmented polygons 2. Screen FRI polygons to curate an optimal dataset to use for imputation 3. Run imputation on FRI polygons ONLY to assess imputation performance 3a. Create functions needed 3b. Run the imputation and assess performance 4. Run imputation on GRM polygon dataset to derive estimates of age and species composition 4a. Figures of Forest Stand Age 4b. Figures of Forest Stand 3-Species Classification 4c. Figures of Forest Stand 5-Species Classification 4d. Density Plots of Forest Stand Age 4e. Distribution of 3-Species Classification 4f. Distribution of 5-Species Classification", " Imputation Intro This page provides an example of the imputation approach used to estimate age and species composition in newly-generated forest stands. The imputation is based on a k-nearest neighbor algorithm. “Link” variables between the photo-interpreted FRI and Generic Region Merging (GRM) generated forest stands are identified and for each GRM forest polygon, the k-nearest neighbor FRI polygons that minimize the Euclidean distance of the link variables are identified and are used to impute age and species composition for the new polygon. If k = 1 the age and species variables are imputed directly from the best matching polygon. If k &gt; 1 age is imputed as the mean age of k-matching polygons and species variables are imputed as the mode of k-matching polygons. The basic workflow is as follows: Run GRM Segmentation to derive new polygon dataset (see previous posts) Extract LiDAR attributes in FRI polygons and GRM segmented polygons Screen FRI polygons to curate an optimal dataset to use for imputation Run imputation on FRI polygons ONLY to assess imputation performance Run imputation on GRM polygon dataset to derive estimates of age and species composition 1. Extract LiDAR attributes in FRI polygons and newly derived polygons Before running imputation we need to extract LiDAR attributes in all FRI polygons and GRM segmented polygons. For this example, we only extract the attributes we will use in the imputation (listed below) as well as the attributes needed for FRI polygon data screening in section 2 of this walk-through. The value extracted for each polygon is the median cell value, weighted by the fraction of each cell that is covered by the polygon. The variables used in the imputation algorithm are as follows, and were selected with guidance from previous works as well as a sensitivity analysis: avg: Average height of returns (&gt; 1.3 m classified as vegetation ??) zsd: Standard deviation of returns height (&gt; 1.3 m classified as vegetation ??) rumple: Ratio of canopy outer surface area to ground surface area zpcum8: Cumulative percentage of LiDAR returns found in 80% percentile of LiDAR height x and y: Coordinates of polygon centroid red_edge_2: Sentinel 2 surface reflectance band (740 nm) p95: 95th percentile of LiDAR height returns &gt; 1.3 m classified as vegetation depth_q25: 25th percentile of signal attenuation depth of all returns 1a. Extract attributes in FRI polygons # load packages library(terra) library(tidyverse) library(exactextractr) library(sf) library(magrittr) library(gridExtra) # load FRI polygons poly &lt;- vect(&#39;D:/ontario_inventory/romeo/RMF_EFI_layers/Polygons Inventory/RMF_PolygonForest.shp&#39;) # convert to df dat_fri &lt;- as.data.frame(poly) # cbind centroids to dat dat_fri &lt;- cbind(dat_fri, centroids(poly) %&gt;% crds) # load LiDAR datasets we need to extract over polygons # create named vector with variable names and data links lidar &lt;- c(&#39;p95&#39; = &#39;D:/ontario_inventory/romeo/RMF_EFI_layers/SPL100 metrics/RMF_20m_T130cm_p95.tif&#39;, &#39;avg&#39; = &#39;D:/ontario_inventory/romeo/RMF_EFI_layers/SPL100 metrics/RMF_20m_T130cm_avg.tif&#39;, &#39;zsd&#39; = &#39;D:/ontario_inventory/romeo/RMF_EFI_layers/SPL100 metrics/RMF_20m_T130cm_std.tif&#39;, &#39;rumple&#39; = &#39;D:/ontario_inventory/romeo/SPL metrics/Z_METRICS_MOSAIC/individual/RMF_RUMPLE_MOSAIC_r_rumple.tif&#39;, &#39;zpcum8&#39; = &#39;D:/ontario_inventory/romeo/SPL metrics/Z_METRICS_MOSAIC/individual/RMF_Z_METRICS_MOSAIC_zpcum8.tif&#39;, #&#39;depth_q25&#39; = &#39;D:/ontario_inventory/romeo/SPL metrics/Z_METRICS_MOSAIC/individual/RMF_SAD_METRICS_MOSAIC_depth_q25.tif&#39;, &#39;red_edge_2&#39; = &#39;D:/ontario_inventory/romeo/Sentinel/red_edge_2.tif&#39;, &#39;cc&#39; = &#39;D:/ontario_inventory/romeo/RMF_EFI_layers/SPL100 metrics/RMF_20m_T130cm_2m_cov.tif&#39;) # loop through LiDAR attributes to extract values for (i in seq_along(lidar)) { # load LiDAR rasters as raster stack lidar_ras &lt;- rast(lidar[i]) # project poly to crs of raster poly_ras &lt;- project(poly, lidar_ras) # convert to sf poly_ras &lt;- st_as_sf(poly_ras) #extract median values vec &lt;- exact_extract(lidar_ras, poly_ras, &#39;median&#39;) # aggregate into data frame if(i == 1){ vec_df &lt;- as.data.frame(vec) } else{ vec_df &lt;- cbind(vec_df, as.data.frame(vec)) } } # change column names of extracted attribute data frame colnames(vec_df) &lt;- names(lidar) # add LiDAR attributes to FRI polygon data frame dat_fri &lt;- cbind(dat_fri, vec_df) # add 2018 age values dat_fri$AGE2018 &lt;- 2018 - dat_fri$YRORG # save extracted dataframe for fast rebooting save(dat_fri, file = &#39;D:/ontario_inventory/imputation/example/dat_fri_extr.RData&#39;) 1b. Extract attributes in newly segmented polygons # load GRM segmented polygons poly &lt;- vect(&#39;D:/ontario_inventory/segmentation/grm/shp/grm_10_01_05.shp&#39;) # convert to df dat_grm &lt;- as.data.frame(poly) # cbind centroids to dat dat_grm &lt;- cbind(dat_grm, centroids(poly) %&gt;% crds) # remove p95 and cc as we&#39;ll re calculate here for consistency dat_grm %&lt;&gt;% select(-c(p95, cc)) # load LiDAR datasets we need to extract over polygons # create named vector with variable names and data links lidar &lt;- c(&#39;p95&#39; = &#39;D:/ontario_inventory/romeo/RMF_EFI_layers/SPL100 metrics/RMF_20m_T130cm_p95.tif&#39;, &#39;avg&#39; = &#39;D:/ontario_inventory/romeo/RMF_EFI_layers/SPL100 metrics/RMF_20m_T130cm_avg.tif&#39;, &#39;zsd&#39; = &#39;D:/ontario_inventory/romeo/RMF_EFI_layers/SPL100 metrics/RMF_20m_T130cm_std.tif&#39;, &#39;rumple&#39; = &#39;D:/ontario_inventory/romeo/SPL metrics/Z_METRICS_MOSAIC/individual/RMF_RUMPLE_MOSAIC_r_rumple.tif&#39;, &#39;zpcum8&#39; = &#39;D:/ontario_inventory/romeo/SPL metrics/Z_METRICS_MOSAIC/individual/RMF_Z_METRICS_MOSAIC_zpcum8.tif&#39;, #&#39;depth_q25&#39; = &#39;D:/ontario_inventory/romeo/SPL metrics/Z_METRICS_MOSAIC/individual/RMF_SAD_METRICS_MOSAIC_depth_q25.tif&#39;, &#39;red_edge_2&#39; = &#39;D:/ontario_inventory/romeo/Sentinel/red_edge_2.tif&#39;, &#39;cc&#39; = &#39;D:/ontario_inventory/romeo/RMF_EFI_layers/SPL100 metrics/RMF_20m_T130cm_2m_cov.tif&#39;) # loop through LiDAR attributes to extract values for (i in seq_along(lidar)) { # load LiDAR rasters as raster stack lidar_ras &lt;- rast(lidar[i]) # project poly to crs of raster poly_ras &lt;- project(poly, lidar_ras) # convert to sf poly_ras &lt;- st_as_sf(poly_ras) #extract median values vec &lt;- exact_extract(lidar_ras, poly_ras, &#39;median&#39;) # aggregate into data frame if(i == 1){ vec_df &lt;- as.data.frame(vec) } else{ vec_df &lt;- cbind(vec_df, as.data.frame(vec)) } } # change column names of extracted attribute data frame colnames(vec_df) &lt;- names(lidar) # add LiDAR attributes to FRI polygon data frame dat_grm &lt;- cbind(dat_grm, vec_df) # save extracted data frame for fast rebooting save(dat_grm, file = &#39;D:/ontario_inventory/imputation/example/grm_10_01_05_extr.RData&#39;) # clear workspace rm(list=ls()) 2. Screen FRI polygons to curate an optimal dataset to use for imputation In order to ensure the best possible imputation results, it is important to screen the FRI dataset and remove polygons that do not fit certain data quality criteria, or are not representative of forest stands. The current criteria being used are: a) POLYTYPE == ‘FOR’ b) polygon &gt;= 50% forested landcover c) p95 (95th percentile of LiDAR height returns) &gt;= 5 meters (definition of ‘forest’) d) Canopy cover (% of returns &gt; 2 m) &gt;= 50% # load FRI polygons poly &lt;- vect(&#39;D:/ontario_inventory/romeo/RMF_EFI_layers/Polygons Inventory/RMF_PolygonForest.shp&#39;) # load FRI polygon data frame load(&#39;D:/ontario_inventory/imputation/example/dat_fri_extr.RData&#39;) ################################## ### SCREEN FOR POLYTYPE == FOR ### ################################## # filter POLYTYPE == &#39;FOR&#39; dat_fri &lt;- filter(dat_fri, POLYTYPE == &#39;FOR&#39;) poly_fri &lt;- poly[poly$POLYTYPE == &#39;FOR&#39;] #################################################### ### SCREEN FOR POLYGON &gt;= 50% FORESTED LANDCOVER ### #################################################### # load VLCE 2.0 landcover dataset from 2018 lc &lt;- rast(&#39;D:/ontario_inventory/VLCE/CA_forest_VLCE2_2018_CLIPPED.tif&#39;) # project poly to crs of raster poly_lc &lt;- project(poly_fri, lc) # convert to sf poly_lcsf &lt;- st_as_sf(poly_lc) # extract landcover values lc_poly &lt;- exact_extract(lc, poly_lcsf) # set landcover class key lc_key &lt;- c(`20` = &#39;Water&#39;, `31` = &#39;Snow/Ice&#39;, `32` = &#39;Rock/Rubble&#39;, `33` = &#39;Exposed/Barren Land&#39;, `40` = &#39;Bryoids&#39;, `50` = &#39;Shrubland&#39;, `80` = &#39;Wetland&#39;, `81` = &#39;Wetland-Treed&#39;, `100` = &#39;Herbs&#39;, `210` = &#39;Coniferous&#39;, `220` = &#39;Broadleaf&#39;, `230` = &#39;Mixed Wood&#39;) # # find number of unique lc types in each polygon # # apply over list # lc_uni &lt;- sapply(lc_poly, function(x){ # x$value &lt;- recode(x$value, !!!lc_key) # x %&lt;&gt;% filter(coverage_fraction &gt;= 0.5) # return(length(unique(x$value))) # }) # set landcover class key with single forested class lc_key_for &lt;- c(`20` = &#39;Water&#39;, `31` = &#39;Snow/Ice&#39;, `32` = &#39;Rock/Rubble&#39;, `33` = &#39;Exposed/Barren Land&#39;, `40` = &#39;Bryoids&#39;, `50` = &#39;Shrubland&#39;, `80` = &#39;Wetland&#39;, `81` = &#39;Forest&#39;, `100` = &#39;Herbs&#39;, `210` = &#39;Forest&#39;, `220` = &#39;Forest&#39;, `230` = &#39;Forest&#39;) # find pixels with forest at least 50% of pixel # apply over list lc_dom_for &lt;- sapply(lc_poly, function(x){ x$value &lt;- recode(x$value, !!!lc_key_for) x &lt;- x %&gt;% group_by(value) %&gt;% summarize(sum = sum(coverage_fraction)) m &lt;- x$value[which(x$sum == max(x$sum))] if((length(m) == 1) &amp; (m == &#39;Forest&#39;)[1]){ if(x$sum[x$value == m]/sum(x$sum) &gt;= 0.5){ return(&#39;Yes&#39;) }else{return(&#39;No&#39;)} }else{return(&#39;No&#39;)} }) # add into FRI data frame dat_fri &lt;- dat_fri %&gt;% add_column(dom_for = lc_dom_for) # subset FRI data frame based on whether polygon dominated by forest dat_dom_for &lt;- dat_fri[dat_fri$dom_for == &#39;Yes&#39;,] ################################## ### SCREEN FOR P95 &gt;= 5 METERS ### ################################## # subset FRI data frame dat_p95 &lt;- dat_fri[dat_fri$p95 &gt;= 5,] ############################ ### SCREEN FOR CC &gt;= 50% ### ############################ # subset FRI data frame dat_cc &lt;- dat_fri[dat_fri$cc &gt;= 50,] ############################################ ### COMBINE INTERSECTION OF DATA SCREENS ### ############################################ # first combine only by POLYID dat_fri_scr &lt;- intersect(dat_dom_for %&gt;% subset(select = POLYID), dat_p95 %&gt;% subset(select = POLYID)) %&gt;% intersect(., dat_cc %&gt;% subset(select = POLYID)) # load full data frame attributes dat_fri_scr &lt;- dat_fri[dat_fri$POLYID %in% dat_fri_scr$POLYID,] # save extracted data frame for fast rebooting save(dat_fri_scr, file = &#39;D:/ontario_inventory/imputation/example/dat_fri_scr.RData&#39;) # clear workspace rm(list=ls()) 3. Run imputation on FRI polygons ONLY to assess imputation performance The goal of this imputation procedure is to estimate age and species composition in newly segmented forest polygons. But it is also important to assess the performance of the algorithm. To do this, we can conduct the imputation over the FRI dataset ONLY. For each FRI polygon, we find the k-nearest neighbor matches, and calculate the age and species composition to impute. We can then compare the observed age and species composition of the polygon to the imputed values. Note we have to do this calculation on the FRI dataset alone because we do not have observed age and species composition values for the GRM segmented polygons. Also note that ALL attributes are imputed from the same k-nearest neighbors. The algorithm is not run for individual attributes. We present the performance of numeric attributes (age as well as the variables used to conduct the imputation algorithm) as Mean Absolute Error (MAE) and Mean Absolute Percentage Error (MAPE). MAE gives an indication of performance in the units of each attribute (such as Age) while MAPE gives a percentage error that can be compared across variables. For species composition, we report the percent of observed and imputed values that match (Accuracy). Species composition is broken down into several distinct attributes: Working group First dominant species (from FRI SPCOMP attribute) Second dominant species (from FRI SPCOMP attribute) 3-Group species classification (softwood, mixedwood, hardwood) 5-Group species classification (jack pine dominated, black spruce dominated, mixed conifer, mixedwood, hardwood) 3a. Create functions needed #################################################### ###FUNCTIONS TO RUN K NEAREST NEIGHBOR IMPUTATION### #################################################### # load packages library(RANN) library(reshape2) # create mode function getmode &lt;- function(v) { uniqv &lt;- unique(v) uniqv[which.max(tabulate(match(v, uniqv)))] } # create mae function mae &lt;- function(obs, est){ sum(abs(obs - est)) / length(obs) } # create mape function mape &lt;- function(obs, est){ sum(abs((obs - est) / obs)) / length(obs) * 100 } # create knn function run_knn_fri &lt;- function(dat, vars, k) { # subset data dat_nn &lt;- dat %&gt;% select(all_of(vars)) # scale for nn computation dat_nn_scaled &lt;- dat_nn %&gt;% scale # run nearest neighbor nn &lt;- nn2(dat_nn_scaled, dat_nn_scaled, k = k + 1) # get nn indices nni &lt;- nn[[1]][, 2:(k + 1)] # add vars to tibble # take mean/mode if k &gt; 1 if(k &gt; 1){ for(i in seq_along(vars)){ if(i == 1){ nn_tab &lt;- tibble(!!vars[i] := dat_nn[,i], !!str_c(vars[i], &#39;_nn&#39;) := apply(nni, MARGIN = 1, FUN = function(x){ mean(dat_nn[x, i]) })) }else{ nn_tab %&lt;&gt;% mutate(!!vars[i] := dat_nn[,i], !!str_c(vars[i], &#39;_nn&#39;) := apply(nni, MARGIN = 1, FUN = function(x){ mean(dat_nn[x, i]) })) } } # add aux vars to tibble nn_tab %&lt;&gt;% mutate(age = dat$AGE2018, wg = dat$WG, sp1 = dat$SP1, sp2 = dat$SP2, group5 = dat$SpeciesGroup2, group3 = dat$SpeciesGroup3, age_nn = apply(nni, MARGIN = 1, FUN = function(x){ mean(dat$AGE2018[x]) }), wg_nn = apply(nni, MARGIN = 1, FUN = function(x){ getmode(dat$WG[x]) }), sp1_nn = apply(nni, MARGIN = 1, FUN = function(x){ getmode(dat$SP1[x]) }), sp2_nn = apply(nni, MARGIN = 1, FUN = function(x){ getmode(dat$SP2[x]) }), group5_nn = apply(nni, MARGIN = 1, FUN = function(x){ getmode(dat$SpeciesGroup2[x]) }), group3_nn = apply(nni, MARGIN = 1, FUN = function(x){ getmode(dat$SpeciesGroup3[x]) })) } # take direct nn if k == 1 if(k == 1){ for(i in seq_along(vars)){ if(i == 1){ nn_tab &lt;- tibble(!!vars[i] := dat_nn[,i], !!str_c(vars[i], &#39;_nn&#39;) := dat_nn[nn[[1]][,2],i]) }else{ nn_tab %&lt;&gt;% mutate(!!vars[i] := dat_nn[,i], !!str_c(vars[i], &#39;_nn&#39;) := dat_nn[nn[[1]][,2],i]) } } # add aux vars to tibble nn_tab %&lt;&gt;% mutate(age = dat$AGE2018, wg = dat$WG, sp1 = dat$SP1, sp2 = dat$SP2, group5 = dat$SpeciesGroup2, group3 = dat$SpeciesGroup3, age_nn = dat$AGE2018[nn[[1]][,2]], wg_nn = dat$WG[nn[[1]][,2]], sp1_nn = dat$SP1[nn[[1]][,2]], sp2_nn = dat$SP2[nn[[1]][,2]], group5_nn = dat$SpeciesGroup2[nn[[1]][,2]], group3_nn = dat$SpeciesGroup3[nn[[1]][,2]]) } # calculate fit metrics for vars for(i in seq_along(vars)){ if(i == 1){ perform_df &lt;- tibble(!!str_c(vars[i], &#39;_mae&#39;) := mae(pull(nn_tab, vars[i]), pull(nn_tab, str_c(vars[i], &#39;_nn&#39;))), !!str_c(vars[i], &#39;_mape&#39;) := mape(pull(nn_tab, vars[i]), pull(nn_tab, str_c(vars[i], &#39;_nn&#39;)))) }else{ perform_df %&lt;&gt;% mutate(!!str_c(vars[i], &#39;_mae&#39;) := mae(pull(nn_tab, vars[i]), pull(nn_tab, str_c(vars[i], &#39;_nn&#39;))), !!str_c(vars[i], &#39;_mape&#39;) := mape(pull(nn_tab, vars[i]), pull(nn_tab, str_c(vars[i], &#39;_nn&#39;)))) } } # calculate rmse for aux vars perform_df %&lt;&gt;% mutate(age_mae = mae(nn_tab$age, nn_tab$age_nn), age_mape = mape(nn_tab$age, nn_tab$age_nn)) # calculate wg accuracy # create df of WG wg &lt;- data.frame(obs = nn_tab$wg, est = nn_tab$wg_nn) # create column of match or not wg$match &lt;- wg$obs == wg$est # add total percent of matching WG to perform_df perform_df &lt;- cbind(perform_df, data.frame(wg_accuracy = NROW(wg[wg$match == T,]) / NROW(wg))) # calculate SP1 accuracy # create df of SP1 sp1 &lt;- data.frame(obs = nn_tab$sp1, est = nn_tab$sp1_nn) # create column of match or not sp1$match &lt;- sp1$obs == sp1$est # add total percent of matching SP1 to perform_df perform_df &lt;- cbind(perform_df, data.frame(sp1_accuracy = NROW(sp1[sp1$match == T,]) / NROW(sp1))) # calculate SP2 accuracy # create df of SP2 sp2 &lt;- data.frame(obs = nn_tab$sp2, est = nn_tab$sp2_nn) # create column of match or not sp2$match &lt;- sp2$obs == sp2$est # add total percent of matching SP2 to perform_df perform_df &lt;- cbind(perform_df, data.frame(sp2_accuracy = NROW(sp2[sp2$match == T,]) / NROW(sp2))) # calculate GROUP3 accuracy # create df of GROUP3 group3 &lt;- data.frame(obs = nn_tab$group3, est = nn_tab$group3_nn) # create column of match or not group3$match &lt;- group3$obs == group3$est # add total percent of matching SP2 to perform_df perform_df &lt;- cbind(perform_df, data.frame(group3_accuracy = NROW(group3[group3$match == T,]) / NROW(group3))) # calculate GROUP5 accuracy # create df of GROUP5 group5 &lt;- data.frame(obs = nn_tab$group5, est = nn_tab$group5_nn) # create column of match or not group5$match &lt;- group5$obs == group5$est # add total percent of matching SP2 to perform_df perform_df &lt;- cbind(perform_df, data.frame(group5_accuracy = NROW(group5[group5$match == T,]) / NROW(group5))) # melt df perform_df &lt;- melt(perform_df) # return df return(perform_df) } 3b. Run the imputation and assess performance ########################### ### LOAD FRI DATA FRAME ### ########################### # load from part 2 above load(&#39;D:/ontario_inventory/imputation/example/dat_fri_scr.RData&#39;) # subset only the attributes we need dat_fri_scr %&lt;&gt;% select(POLYID, AGE2018, SPCOMP, WG, avg, zsd, rumple, zpcum8, x, y, red_edge_2) # remove any polygons with missing values dat_fri_scr &lt;- na.omit(dat_fri_scr) ########################################### ### CALCULATE AND ADD SPCOMP ATTRIBUTES ### ########################################### # parse SPCOMP strings sp &lt;- str_split(dat_fri_scr$SPCOMP, pattern = &quot;\\\\s{2}&quot;) # add first species to dat dat_fri_scr$SP1 &lt;- sapply(sp, FUN = function(x){ str &lt;- x[1] str &lt;- str_sub(str, start = 1, end = 2) return(str) }) # add first species percent to dat dat_fri_scr$SP1P &lt;- sapply(sp, FUN = function(x){ str &lt;- x[2] if(is.na(str)){ str &lt;- 100 } else{ str &lt;- str_sub(str, start = 1, end = 2) } return(str) }) # add second species to dat dat_fri_scr$SP2 &lt;- sapply(sp, FUN = function(x){ str &lt;- x[2] if(is.na(str) == F){ str &lt;- str_sub(str, start = 3, end = 4) } return(str) }) # add second species percent to dat dat_fri_scr$SP2P &lt;- sapply(sp, FUN = function(x){ str &lt;- x[3] if(is.na(str) == F){ str &lt;- str_sub(str, start = 1, end = 2) } return(str) }) # change second species missing values dat_fri_scr$SP2[is.na(dat_fri_scr$SP2)] &lt;- &#39;MIS&#39; dat_fri_scr$SP2P[is.na(dat_fri_scr$SP2P)] &lt;- 0 # load species group data -- calculated in separate code (can provide details) sp_group &lt;- read.csv( &#39;D:/ontario_inventory/romeo/RMF_EFI_layers/Polygons Inventory/RMF_PolygonForest_SPGROUP.shp&#39; ) # change POLYID to numeric dat_fri_scr %&lt;&gt;% mutate(POLYID = as.numeric(POLYID)) sp_group %&lt;&gt;% mutate(POLYID = as.numeric(POLYID)) # join to dat dat_fri_scr &lt;- left_join(dat_fri_scr, sp_group %&gt;% select(POLYID, SpeciesGroup2, SpeciesGroup3), by = &#39;POLYID&#39;) ############################################## ### RUN NEAREST NEIGHBOR IMPUTATION K = 5 ### ############################################## # run_knn function already created # we use top_height, cc, red_edge_2 in the algorithm perf &lt;- run_knn_fri(dat_fri_scr, c(&#39;avg&#39;, &#39;zsd&#39;, &#39;rumple&#39;, &#39;zpcum8&#39;, &#39;x&#39;, &#39;y&#39;, &#39;red_edge_2&#39;), k = 5) # round values perf %&lt;&gt;% mutate(value = round(value, 2)) # display results knitr::kable(perf, caption = &quot;Imputation Performance of FRI Forest Stand Polygons&quot;, label = NA) EDIT! *** Mean Absolute Percent Error (MAPE) of the imputation attributes (p95, rumple, zpcum8, depth_q25, x, y, red_edge_2) is below 5% for all attributes. These are low values, which demonstrate that the imputation algorithm is finding optimal matches within the database of available FRI polygons. The Mean Absolute Error of Age is 16.27, and the MAPE is 38.71 percent. Accuracy of first species classification (sp1) is 67%, and a much lower 36% for second species. Species classification with 3 and 5 classes have respective accuracies of 74% and 63%. *** 4. Run imputation on GRM polygon dataset to derive estimates of age and species composition The last step is to run the imputation between the screened FRI data frame and the GRM segmented polygons. For each GRM segmented polygon, the k-nearest neighbors in the FRI data are found and used to impute age and species composition. Note we do not conduct imputation on all the GRM segmented polygons, but only the polygons that have &gt;= 50% forested landcover, p95 &gt;= 5 meters, and canopy cover &gt;= 50% (same criteria as FRI data screening conducted above in step 2). Although we cannot assess performance of age and species composition when imputing into the GRM segmented polygons, we can still assess the fit of the variables used in the imputation: avg, zsd, rumple, zpcum8, x, y, and Sentinel red_edge_2. We can also review maps and distributions comparing FRI age/species composition against the same attributes imputed into GRM segmented polygons. # load additional packages library(viridis) library(scales) library(janitor) # load GRM polygon data frame load(&#39;D:/ontario_inventory/imputation/example/grm_10_01_05_extr.RData&#39;) # screen for forested polygons dat_grm_scr &lt;- dat_grm %&gt;% filter(dom_for == &#39;Yes&#39;, p95 &gt;= 5, cc &gt;= 50) # create data frame for grm and fri metrics used in imputation dat_grm_imp &lt;- dat_grm_scr %&gt;% select(id, avg, zsd, rumple, zpcum8, x, y, red_edge_2) %&gt;% na.omit dat_fri_imp &lt;- dat_fri_scr %&gt;% select(avg, zsd, rumple, zpcum8, x, y, red_edge_2) %&gt;% na.omit # need to combine and scale all values together then separate again dat_comb_scaled &lt;- rbind(dat_grm_imp %&gt;% select(-id), dat_fri_imp) %&gt;% scale dat_grm_scaled &lt;- dat_comb_scaled[1:NROW(dat_grm_imp),] dat_fri_scaled &lt;- dat_comb_scaled[(NROW(dat_grm_imp)+1):(NROW(dat_grm_imp)+NROW(dat_fri_imp)),] # run nearest neighbor imputation k = 5 nn &lt;- nn2(dat_fri_scaled, dat_grm_scaled, k = 5) # get nn indices nni &lt;- nn[[1]] # add imputed attributes into GRM imputation data frame dat_grm_imp %&lt;&gt;% add_column( avg_imp = apply( nni, MARGIN = 1, FUN = function(x) { mean(dat_fri_imp[x, &#39;avg&#39;]) } ), zsd_imp = apply( nni, MARGIN = 1, FUN = function(x) { mean(dat_fri_imp[x, &#39;zsd&#39;]) } ), rumple_imp = apply( nni, MARGIN = 1, FUN = function(x) { mean(dat_fri_imp[x, &#39;rumple&#39;]) } ), zpcum8_imp = apply( nni, MARGIN = 1, FUN = function(x) { mean(dat_fri_imp[x, &#39;zpcum8&#39;]) } ), x_imp = apply( nni, MARGIN = 1, FUN = function(x) { mean(dat_fri_imp[x, &#39;x&#39;]) } ), y_imp = apply( nni, MARGIN = 1, FUN = function(x) { mean(dat_fri_imp[x, &#39;y&#39;]) } ), red_edge_2_imp = apply( nni, MARGIN = 1, FUN = function(x) { mean(dat_fri_imp[x, &#39;red_edge_2&#39;]) } ), age = apply( nni, MARGIN = 1, FUN = function(x) { mean(dat_fri_scr[x, &#39;AGE2018&#39;]) } ), wg = apply( nni, MARGIN = 1, FUN = function(x) { getmode(dat_fri_scr[x, &#39;WG&#39;]) } ), sp1 = apply( nni, MARGIN = 1, FUN = function(x) { getmode(dat_fri_scr[x, &#39;SP1&#39;]) } ), sp2 = apply( nni, MARGIN = 1, FUN = function(x) { getmode(dat_fri_scr[x, &#39;SP2&#39;]) } ), class3 = apply( nni, MARGIN = 1, FUN = function(x) { getmode(dat_fri_scr[x, &#39;SpeciesGroup3&#39;]) } ), class5 = apply( nni, MARGIN = 1, FUN = function(x) { getmode(dat_fri_scr[x, &#39;SpeciesGroup2&#39;]) } ) ) # add values back into main GRM data frame (missing values for polygons not # included in the imputation) dat_grm &lt;- left_join(dat_grm, dat_grm_imp) # calculate performance across imputation attributes perf &lt;- tibble(avg_mae = mae(dat_grm_imp$avg, dat_grm_imp$avg_imp), avg_mape = mape(dat_grm_imp$avg, dat_grm_imp$avg_imp), zsd_mae = mae(dat_grm_imp$zsd, dat_grm_imp$zsd_imp), zsd_mape = mape(dat_grm_imp$zsd, dat_grm_imp$zsd_imp), rumple_mae = mae(dat_grm_imp$rumple, dat_grm_imp$rumple_imp), rumple_mape = mape(dat_grm_imp$rumple, dat_grm_imp$rumple_imp), zpcum8_mae = mae(dat_grm_imp$zpcum8, dat_grm_imp$zpcum8_imp), zpcum8_mape = mape(dat_grm_imp$zpcum8, dat_grm_imp$zpcum8_imp), x_mae = mae(dat_grm_imp$x, dat_grm_imp$x_imp), x_mape = mape(dat_grm_imp$x, dat_grm_imp$x_imp), y_mae = mae(dat_grm_imp$y, dat_grm_imp$y_imp), y_mape = mape(dat_grm_imp$y, dat_grm_imp$y_imp), red_edge_2_mae = mae(dat_grm_imp$red_edge_2, dat_grm_imp$red_edge_2_imp), red_edge_2_mape = mape(dat_grm_imp$red_edge_2, dat_grm_imp$red_edge_2_imp) ) %&gt;% melt # round to two decimal places perf %&lt;&gt;% mutate(value = round(value, 2)) # display results of imputation rmsd knitr::kable(perf, caption = &quot;Imputation Performance between FRI and GRM Forest Stand Polygons&quot;, label = NA) 4a. Figures of Forest Stand Age # load GRM polygons poly_grm &lt;- vect(&#39;D:/ontario_inventory/segmentation/grm/shp/grm_10_01_05.shp&#39;) # add new data frame to polygons values(poly_grm) &lt;- dat_grm # save grm polygon output writeVector(poly_grm, &#39;D:/ontario_inventory/imputation/example/grm_10_01_05_imp.shp&#39;, overwrite = T) # load FRI polygons poly_fri &lt;- vect(&#39;D:/ontario_inventory/romeo/RMF_EFI_layers/Polygons Inventory/RMF_PolygonForest.shp&#39;) # set age == 0 to NA poly_fri$AGE[poly_fri$AGE == 0] &lt;- NA # load species group data -- calculated in separate code (can provide details) sp_group &lt;- read.csv( &#39;D:/ontario_inventory/romeo/RMF_EFI_layers/Polygons Inventory/RMF_PolygonForest_SPGROUP.shp&#39; ) # load poly_Fri dataframe dat_fri &lt;- as.data.frame(poly_fri) # change POLYID to numeric dat_fri %&lt;&gt;% mutate(POLYID = as.numeric(POLYID)) sp_group %&lt;&gt;% mutate(POLYID = as.numeric(POLYID)) # rename species groups sp_group %&lt;&gt;% rename(class3 = SpeciesGroup3, class5 = SpeciesGroup2) # join to dat dat_fri &lt;- left_join(dat_fri, sp_group %&gt;% select(POLYID, class3, class5), by = &#39;POLYID&#39;) # update age to 2018 dat_fri$AGE2018 &lt;- 2018 - dat_fri$YRORG # re-input attributes into FRI polygons values(poly_fri) &lt;- dat_fri rm(dat_fri) # since we only have values of age and species comp for dom_fom == yes # and p95 &gt;= 5 m we should only compare the screened FRI polygons that # contain those same attributes poly_fri$AGE2018[!(poly_fri$POLYID %in% dat_fri_scr$POLYID)] &lt;- NA poly_fri$class3[!(poly_fri$POLYID %in% dat_fri_scr$POLYID)] &lt;- NA poly_fri$class5[!(poly_fri$POLYID %in% dat_fri_scr$POLYID)] &lt;- NA # plot age par(mfrow=c(2,1)) plot(poly_grm, &#39;age&#39;, col = viridis(14), type = &#39;interval&#39;, breaks = seq(0, 140, 10), plg = list(x = &#39;topright&#39;, cex = 2, title = &#39;Age&#39;), main = &#39;&#39;) title(main = &#39;Imputed Age of GRM Segmented Forest Stands&#39;, cex.main = 3) plot(poly_fri, &#39;AGE2018&#39;, col = viridis(14), type = &#39;interval&#39;, breaks = seq(0, 140, 10), plg = list(x = &#39;topright&#39;, cex = 2, title = &#39;Age&#39;), main = &#39;&#39;) title(main = &#39;Age of FRI Forest Stands&#39;, cex.main = 3) 4b. Figures of Forest Stand 3-Species Classification # plot group of 3 species par(mfrow=c(2,1)) plot(poly_grm, &#39;class3&#39;, col = viridis(3), type = &#39;classes&#39;, plg = list(x = &#39;topright&#39;, cex = 2, title = &#39;Species Class&#39;), main = &#39;&#39;) title(main = &#39;Imputed Species Class (3) of GRM Segmented Forest Stands&#39;, cex.main = 3) plot(poly_fri, &#39;class3&#39;, col = viridis(3), type = &#39;classes&#39;, plg = list(x = &#39;topright&#39;, cex = 2, title = &#39;Species Class&#39;), main = &#39;&#39;) title(main = &#39;Species Class (3) FRI Forest Stands&#39;, cex.main = 3) 4c. Figures of Forest Stand 5-Species Classification # plot group of 5 species par(mfrow=c(2,1)) plot(poly_grm, &#39;class5&#39;, col = viridis(5), type = &#39;classes&#39;, plg = list(x = &#39;topright&#39;, cex = 2, title = &#39;Species Class&#39;), main = &#39;&#39;) title(main = &#39;Imputed Species Class (5) of GRM Segmented Forest Stands&#39;, cex.main = 3) plot(poly_fri, &#39;class5&#39;, col = viridis(5), type = &#39;classes&#39;, plg = list(x = &#39;topright&#39;, cex = 2, title = &#39;Species Class&#39;), main = &#39;&#39;) title(main = &#39;Species Class (5) FRI Forest Stands&#39;, cex.main = 3) 4d. Density Plots of Forest Stand Age # density plots of age p1 &lt;- ggplot(dat_grm, aes(x = age)) + geom_density(fill = &#39;grey&#39;) + geom_vline(aes(xintercept = median(age, na.rm = T)), linetype = &quot;dashed&quot;, size = 0.6) + xlim(c(0,200)) + ylim(c(0, 0.02)) + theme_bw() + xlab(&#39;Age&#39;) + ylab(&#39;Density&#39;) + ggtitle(&#39;Imputed Age of GRM Segmented Forest Stands&#39;) + theme(text = element_text(size = 25), plot.title = element_text(size=30)) p2 &lt;- ggplot(as.data.frame(poly_fri), aes(x = AGE2018)) + geom_density(fill = &#39;grey&#39;) + geom_vline(aes(xintercept = median(AGE, na.rm = T)), linetype = &quot;dashed&quot;, size = 0.6) + xlim(c(0, 200)) + ylim(c(0, 0.02)) + theme_bw() + xlab(&#39;Age&#39;) + ylab(&#39;Density&#39;) + ggtitle(&#39;Age of FRI Forest Stands&#39;) + theme(text = element_text(size = 25), plot.title = element_text(size=30)) grid.arrange(p1, p2, ncol = 2) 4e. Distribution of 3-Species Classification # distribution of 3 species classes # create data frame for GRM 3 classes dat_grm_c3 &lt;- dat_grm %&gt;% tabyl(class3) %&gt;% filter(is.na(class3) == F) %&gt;% arrange(desc(class3)) %&gt;% mutate(prop = n / sum(.$n)*100) %&gt;% mutate(ypos = cumsum(prop) - 0.5*prop) %&gt;% mutate(lbl = round(prop)) # create data frame for FRI 3 classes dat_fri_c3 &lt;- poly_fri %&gt;% as.data.frame %&gt;% tabyl(class3) %&gt;% filter(is.na(class3) == F) %&gt;% arrange(desc(class3)) %&gt;% mutate(prop = n / sum(.$n)*100) %&gt;% mutate(ypos = cumsum(prop) - 0.5*prop) %&gt;% mutate(lbl = round(prop)) # plot p1 &lt;- ggplot(dat_grm_c3, aes(x = &quot;&quot;, y = prop, fill = class3)) + geom_bar(width = 1, stat = &quot;identity&quot;) + coord_polar(&quot;y&quot;, start = 0) + theme_void() + geom_text(aes(y = ypos, label = str_c(lbl, &quot;%&quot;)), size = 15) + theme(legend.title = element_text(size = 30), legend.text = element_text(size = 20), legend.key.width = unit(2, &#39;cm&#39;), plot.title = element_text(size=30)) + labs(fill = &quot;3 Species Classification&quot;) + ggtitle(&quot;Imputed 3 Species Classification \\nof GRM Segmented Forest Stands&quot;) p2 &lt;- ggplot(dat_fri_c3, aes(x = &quot;&quot;, y = prop, fill = class3)) + geom_bar(width = 1, stat = &quot;identity&quot;) + coord_polar(&quot;y&quot;, start = 0) + theme_void() + geom_text(aes(y = ypos, label = str_c(lbl, &quot;%&quot;)), size = 15) + theme(legend.title = element_text(size = 30), legend.text = element_text(size = 20), legend.key.width = unit(2, &#39;cm&#39;), plot.title = element_text(size=30)) + labs(fill = &quot;3 Species Classification&quot;) + ggtitle(&quot;3 Species Classification \\nof FRI Forest Stands&quot;) grid.arrange(p1, p2, ncol = 2) 4f. Distribution of 5-Species Classification # distribution of 5 species classes # create data frame for GRM 5 classes dat_grm_c5 &lt;- dat_grm %&gt;% tabyl(class5) %&gt;% filter(is.na(class5) == F) %&gt;% arrange(desc(class5)) %&gt;% mutate(prop = n / sum(.$n)*100) %&gt;% mutate(ypos = cumsum(prop) - 0.5*prop) %&gt;% mutate(lbl = round(prop)) # create data frame for FRI 3 classes dat_fri_c5 &lt;- poly_fri %&gt;% as.data.frame %&gt;% tabyl(class5) %&gt;% filter(is.na(class5) == F) %&gt;% arrange(desc(class5)) %&gt;% mutate(prop = n / sum(.$n)*100) %&gt;% mutate(ypos = cumsum(prop) - 0.5*prop) %&gt;% mutate(lbl = round(prop)) # plot p1 &lt;- ggplot(dat_grm_c5, aes(x = &quot;&quot;, y = prop, fill = class5)) + geom_bar(width = 1, stat = &quot;identity&quot;) + coord_polar(&quot;y&quot;, start = 0) + theme_void() + geom_text(aes(y = ypos, label = str_c(lbl, &quot;%&quot;)), size = 15) + theme(legend.title = element_text(size = 30), legend.text = element_text(size = 20), legend.key.width = unit(2, &#39;cm&#39;), plot.title = element_text(size=30)) + labs(fill = &quot;5 Species Classification&quot;) + ggtitle(&quot;Imputed 5 Species Classification \\nof GRM Segmented Forest Stands&quot;) p2 &lt;- ggplot(dat_fri_c5, aes(x = &quot;&quot;, y = prop, fill = class5)) + geom_bar(width = 1, stat = &quot;identity&quot;) + coord_polar(&quot;y&quot;, start = 0) + theme_void() + geom_text(aes(y = ypos, label = str_c(lbl, &quot;%&quot;)), size = 15) + theme(legend.title = element_text(size = 30), legend.text = element_text(size = 20), legend.key.width = unit(2, &#39;cm&#39;), plot.title = element_text(size=30)) + labs(fill = &quot;5 Species Classification&quot;) + ggtitle(&quot;5 Species Classification \\nof FRI Forest Stands&quot;) grid.arrange(p1, p2, ncol = 2) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
